{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c249c2d",
   "metadata": {},
   "source": [
    "## Assignment No: 9\n",
    "## Name: Nghia Lam\n",
    "## UTA ID: 1001699317"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b00fe",
   "metadata": {},
   "source": [
    "## INSTRUCTIONS \n",
    "\n",
    "Every learner should submit his/her own homework solutions. However, you are allowed to discuss the homework with each other– but everyone must submit his/her own solution; you may not copy someone else’s solution. \n",
    "\n",
    "Follow the prompts in the attached jupyter notebook. We are using a clean and modified version of the auto imports dataset (Description of the original dataset is in the cell bellow). Download the auto_imp.csv file from Canvas and put it in your working directory. Don't forget to add libraries to use in your analysis. You can use the code as a guide that was provided in the class. \n",
    "\n",
    "Add markdown cells to your analysis to include your solutions, comments, answers. Add as many cells as you need, for easy readability comment when possible. \n",
    "\n",
    "**Note:** You need to use your code from the previous assignment for question 1.\n",
    "\n",
    "Submission: Run all your code cells and export the file as HTML. Submit a zip of your .ipynb file and HTML file. Add your name and UTA ID in the markdown cell above.\n",
    "\n",
    "Good luck!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377d748b",
   "metadata": {},
   "source": [
    "**Title: 1985 Auto Imports Database**\n",
    "\n",
    "Relevant Information:\n",
    "   -- Description\n",
    "      This data set consists of three types of entities: (a) the\n",
    "      specification of an auto in terms of various characteristics, (b)\n",
    "      its assigned insurance risk rating, (c) its normalized losses in use\n",
    "      as compared to other cars.  The second rating corresponds to the\n",
    "      degree to which the auto is more risky than its price indicates.\n",
    "      Cars are initially assigned a risk factor symbol associated with its\n",
    "      price.   Then, if it is more risky (or less), this symbol is\n",
    "      adjusted by moving it up (or down) the scale.  Actuarians call this\n",
    "      process \"symboling\".  A value of +3 indicates that the auto is\n",
    "      risky, -3 that it is probably pretty safe.\n",
    "\n",
    "      The third factor is the relative average loss payment per insured\n",
    "      vehicle year.  This value is normalized for all autos within a\n",
    "      particular size classification (two-door small, station wagons,\n",
    "      sports/speciality, etc...), and represents the average loss per car\n",
    "      per year.\n",
    "\n",
    "   -- Note: Several of the attributes in the database could be used as a\n",
    "            \"class\" attribute.\n",
    "\n",
    "5. Number of Instances: 205\n",
    "\n",
    "6. Number of Attributes: 26 total\n",
    "   -- 15 continuous\n",
    "   -- 1 integer\n",
    "   -- 10 nominal\n",
    "\n",
    "7. Attribute Information:     \n",
    "     Attribute:                Attribute Range:\n",
    "     ------------------        -----------------------------------------------\n",
    "  1. symboling:                -3, -2, -1, 0, 1, 2, 3.\n",
    "  2. normalized-losses:        continuous from 65 to 256.\n",
    "  3. make:                     alfa-romero, audi, bmw, chevrolet, dodge, honda,isuzu, jaguar, mazda, mercedes-benz, mercury, mitsubishi, nissan, peugot, plymouth, porsche, renault, saab, subaru, toyota,volkswagen, volvo\n",
    "  4. fuel-type:                diesel, gas.\n",
    "  5. aspiration:               std, turbo.\n",
    "  6. num-of-doors:             four, two.\n",
    "  7. body-style:               hardtop, wagon, sedan, hatchback, convertible.\n",
    "  8. drive-wheels:             4wd, fwd, rwd.\n",
    "  9. engine-location:          front, rear.\n",
    " 10. wheel-base:               continuous from 86.6 120.9.\n",
    " 11. length:                   continuous from 141.1 to 208.1.\n",
    " 12. width:                    continuous from 60.3 to 72.3.\n",
    " 13. height:                   continuous from 47.8 to 59.8.\n",
    " 14. curb-weight:              continuous from 1488 to 4066.\n",
    " 15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor.\n",
    " 16. num-of-cylinders:         eight, five, four, six, three, twelve, two.\n",
    " 17. engine-size:              continuous from 61 to 326.\n",
    " 18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.\n",
    " 19. bore:                     continuous from 2.54 to 3.94.\n",
    " 20. stroke:                   continuous from 2.07 to 4.17.\n",
    " 21. compression-ratio:        continuous from 7 to 23.\n",
    " 22. horsepower:               continuous from 48 to 288.\n",
    " 23. peak-rpm:                 continuous from 4150 to 6600.\n",
    " 24. city-mpg:                 continuous from 13 to 49.\n",
    " 25. highway-mpg:              continuous from 16 to 54.\n",
    " 26. price:                    continuous from 5118 to 45400.\n",
    "\n",
    "8. Missing Attribute Values: (denoted by \"?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a7df56",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e54c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add libraries to use\n",
    "from numpy import where\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "from sklearn.dummy import DummyClassifier\n",
    "#from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4e2d8",
   "metadata": {},
   "source": [
    "**Use the dataset 'auto_imp.csv' from Canvas. Follow the prompts to complete the homework.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "303ca496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =pd.read_csv('auto_imp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49f9f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195 entries, 0 to 194\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   fuel_type    195 non-null    object \n",
      " 1   wheel_base   195 non-null    float64\n",
      " 2   length       195 non-null    float64\n",
      " 3   width        195 non-null    float64\n",
      " 4   heights      195 non-null    float64\n",
      " 5   curb_weight  195 non-null    int64  \n",
      " 6   engine_size  195 non-null    int64  \n",
      " 7   bore         195 non-null    float64\n",
      " 8   stroke       195 non-null    float64\n",
      " 9   comprassion  195 non-null    float64\n",
      " 10  horse_power  195 non-null    int64  \n",
      " 11  peak_rpm     195 non-null    int64  \n",
      " 12  city_mpg     195 non-null    int64  \n",
      " 13  highway_mpg  195 non-null    int64  \n",
      " 14  price        195 non-null    int64  \n",
      "dtypes: float64(7), int64(7), object(1)\n",
      "memory usage: 23.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7356dab7",
   "metadata": {},
   "source": [
    "## 1.1 **Replace ['gas', 'diesel'] string values to [0, 1]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "127b23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code\n",
    "df2=pd.get_dummies(df2, columns=['fuel_type'],drop_first=True, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91e32dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheel_base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>heights</th>\n",
       "      <th>curb_weight</th>\n",
       "      <th>engine_size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>comprassion</th>\n",
       "      <th>horse_power</th>\n",
       "      <th>peak_rpm</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>price</th>\n",
       "      <th>fuel_type_gas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>152</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>2952</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>16845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.8</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3049</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>8.7</td>\n",
       "      <td>160</td>\n",
       "      <td>5300</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>19045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3012</td>\n",
       "      <td>173</td>\n",
       "      <td>3.58</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.8</td>\n",
       "      <td>134</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>21485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3217</td>\n",
       "      <td>145</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>106</td>\n",
       "      <td>4800</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>22470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3062</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>22625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     wheel_base  length  width  heights  curb_weight  engine_size  bore  \\\n",
       "0          88.6   168.8   64.1     48.8         2548          130  3.47   \n",
       "1          88.6   168.8   64.1     48.8         2548          130  3.47   \n",
       "2          94.5   171.2   65.5     52.4         2823          152  2.68   \n",
       "3          99.8   176.6   66.2     54.3         2337          109  3.19   \n",
       "4          99.4   176.6   66.4     54.3         2824          136  3.19   \n",
       "..          ...     ...    ...      ...          ...          ...   ...   \n",
       "190       109.1   188.8   68.9     55.5         2952          141  3.78   \n",
       "191       109.1   188.8   68.8     55.5         3049          141  3.78   \n",
       "192       109.1   188.8   68.9     55.5         3012          173  3.58   \n",
       "193       109.1   188.8   68.9     55.5         3217          145  3.01   \n",
       "194       109.1   188.8   68.9     55.5         3062          141  3.78   \n",
       "\n",
       "     stroke  comprassion  horse_power  peak_rpm  city_mpg  highway_mpg  price  \\\n",
       "0      2.68          9.0          111      5000        21           27  13495   \n",
       "1      2.68          9.0          111      5000        21           27  16500   \n",
       "2      3.47          9.0          154      5000        19           26  16500   \n",
       "3      3.40         10.0          102      5500        24           30  13950   \n",
       "4      3.40          8.0          115      5500        18           22  17450   \n",
       "..      ...          ...          ...       ...       ...          ...    ...   \n",
       "190    3.15          9.5          114      5400        23           28  16845   \n",
       "191    3.15          8.7          160      5300        19           25  19045   \n",
       "192    2.87          8.8          134      5500        18           23  21485   \n",
       "193    3.40         23.0          106      4800        26           27  22470   \n",
       "194    3.15          9.5          114      5400        19           25  22625   \n",
       "\n",
       "     fuel_type_gas  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "..             ...  \n",
       "190              1  \n",
       "191              1  \n",
       "192              1  \n",
       "193              0  \n",
       "194              1  \n",
       "\n",
       "[195 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3851124",
   "metadata": {},
   "source": [
    "## 1.2 : Define your X and y: your dependent variable is fuel_type, the rest of the variables are your independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3735085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "y = df2['fuel_type_gas']\n",
    "X = df2.drop(columns=['fuel_type_gas'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf86f4df",
   "metadata": {},
   "source": [
    "## 1.3 Split your data into training and testing set. Use test_size=0.3, random_state=746 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e6c1b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (136, 14)\n",
      "X_test shape: (59, 14)\n",
      "y_train shape: (136,)\n",
      "y_test shape: (59,)\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=746)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad2fd64",
   "metadata": {},
   "source": [
    "# 2. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3371eae",
   "metadata": {},
   "source": [
    "### 2.1 Use SVM to classify your data. Print/report your confusion matrix, classification report and AUC. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7b82419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 0  9]\n",
      " [ 0 50]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.85      1.00      0.92        50\n",
      "\n",
      "    accuracy                           0.85        59\n",
      "   macro avg       0.42      0.50      0.46        59\n",
      "weighted avg       0.72      0.85      0.78        59\n",
      "\n",
      "AUC: 0.8577777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nghia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nghia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nghia\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "svm_class = SVC()\n",
    "svm_class.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svm_class.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_test,y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "auc = roc_auc_score(y_test,svm_class.decision_function(X_test))\n",
    "print(f\"AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b7403b",
   "metadata": {},
   "source": [
    "### 2.2 Use Random Forest to classify your data. Print/report your confusion matrix, classification report and AUC. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bc4e2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.926\n",
      "[[ 1  8]\n",
      " [ 0 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.11      0.20         9\n",
      "           1       0.86      1.00      0.93        50\n",
      "\n",
      "    accuracy                           0.86        59\n",
      "   macro avg       0.93      0.56      0.56        59\n",
      "weighted avg       0.88      0.86      0.82        59\n",
      "\n",
      "Accuracy: 0.864406779661017\n",
      "Cohen Kappa: 0.175\n",
      "AUC: 0.556\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "rf_class = RandomForestClassifier(n_jobs=-1)\n",
    "gs_rf = GridSearchCV(estimator=rf_class,\n",
    "                     param_grid={'max_depth':np.arange(1,31)},\n",
    "                     cv=5,\n",
    "                     scoring='roc_auc')\n",
    "\n",
    "model9=gs_rf.fit(X_train,y_train)\n",
    "y_1 = gs_rf.predict(X_test)\n",
    "\n",
    "rf_class.fit(X_train,y_train)\n",
    "\n",
    "y_pred = rf_class.predict(X_test)\n",
    "\n",
    "score = f1_score(y_test, y_1, pos_label=1)\n",
    "print('F1 Score: %.3f' % score)\n",
    "\n",
    "print(confusion_matrix(y_test, y_1))\n",
    "print(classification_report(y_test, y_1))\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_1))\n",
    "\n",
    "cohen=metrics.cohen_kappa_score(y_test, y_1)\n",
    "print('Cohen Kappa: %.3f' % cohen)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_1)\n",
    "\n",
    "print('AUC: %.3f' % auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c75879",
   "metadata": {},
   "source": [
    "### 2.3 Compare your results from Assignment 8 and Asisgnment 9 to comment on your findings. Which one(s) did the best job ? What could have been the problem with the ones that did not work? etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44011e38",
   "metadata": {},
   "source": [
    "For both assignment 8 and 9 there was alot of classification that had very good accuracy. I believe that because there is not enough data the accuracy is very high so to change this more data would be needed to check but if we were to pick Naive bayes and logistic would be my pick as they would have the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3740e1a",
   "metadata": {},
   "source": [
    "### 3. Try to fix the inbalanced nature of the data with a tool from the lecture. Run one of the classification methods (preferable one that \"failed\" before) and see if you get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bce5eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2720e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdf64977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6610169491525424\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 4  5]\n",
      " [15 35]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.44      0.29         9\n",
      "           1       0.88      0.70      0.78        50\n",
      "\n",
      "    accuracy                           0.66        59\n",
      "   macro avg       0.54      0.57      0.53        59\n",
      "weighted avg       0.77      0.66      0.70        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#your code\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=50)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "svc_model = SVC(random_state=50)\n",
    "svc_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Making predictions\n",
    "predictions = svc_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print('\\nConfusion Matrix:\\n', confusion_matrix(y_test, predictions))\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc1165",
   "metadata": {},
   "source": [
    "Over sampling for SVC gives a lower accuracy, it seems like oversampling does not work with this classification. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
